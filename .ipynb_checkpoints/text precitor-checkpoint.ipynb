{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a28069ef-7d3b-457f-a6d2-243dbc15b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "text =\"\"\"Data analysis is the process of inspecting, cleansing, transforming, and modeling data with the goal of discovering useful information, informing conclusions, and supporting decision-making.\n",
    "Data analysis has multiple facets and approaches, encompassing diverse techniques under a variety of names, and is used in different business, science, and social science domains.\n",
    "In today's business world, data analysis plays a role in making decisions more scientific and helping businesses operate more effectively.\n",
    "Data mining is a particular data analysis technique that focuses on statistical modeling and knowledge discovery for predictive rather than purely descriptive purposes, while business intelligence covers data analysis that relies heavily on aggregation, focusing mainly on business information.\n",
    "In statistical applications, data analysis can be divided into descriptive statistics, exploratory data analysis (EDA), and confirmatory data analysis (CDA).\n",
    "EDA focuses on discovering new features in the data while CDA focuses on confirming or falsifying existing hypotheses.\n",
    "Predictive analytics focuses on the application of statistical models for predictive forecasting or classification, while text analytics applies statistical, linguistic, and structural techniques to extract and classify information from textual sources, a variety of unstructured data.\n",
    "All of the above are varieties of data analysis.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8c98d336-4f4e-4aba-84e0-d4c9725a6d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1b8de40f-6e8d-4974-83c3-8ba24d564303",
   "metadata": {},
   "outputs": [],
   "source": [
    " # initiate the tokenizer\n",
    "tokenizer =Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4dde2a13-0273-4b1f-b2e2-2b5e138e6504",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([text]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8a201ed1-26ff-44ce-8928-a79652e24b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f499b6a5-5e8d-4b6d-929d-d7d48fae3142",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence=[]\n",
    "for sentence in text.split('\\n'): \n",
    "    tokenize_sentance = tokenizer.texts_to_sequences([sentence])[0]  \n",
    "    for i in range(1,len(tokenize_sentance)): \n",
    "        input_sequence.append(tokenize_sentance[:i+1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cb58f2e2-f6d2-4db0-be49-efb3a31d18b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3],\n",
       " [1, 3, 12],\n",
       " [1, 3, 12, 6],\n",
       " [1, 3, 12, 6, 30],\n",
       " [1, 3, 12, 6, 30, 4],\n",
       " [1, 3, 12, 6, 30, 4, 31],\n",
       " [1, 3, 12, 6, 30, 4, 31, 32],\n",
       " [1, 3, 12, 6, 30, 4, 31, 32, 33],\n",
       " [1, 3, 12, 6, 30, 4, 31, 32, 33, 2],\n",
       " [1, 3, 12, 6, 30, 4, 31, 32, 33, 2, 16],\n",
       " [1, 3, 12, 6, 30, 4, 31, 32, 33, 2, 16, 1],\n",
       " [1, 3, 12, 6, 30, 4, 31, 32, 33, 2, 16, 1, 34],\n",
       " [1, 3, 12, 6, 30, 4, 31, 32, 33, 2, 16, 1, 34, 6],\n",
       " [1, 3, 12, 6, 30, 4, 31, 32, 33, 2, 16, 1, 34, 6, 35],\n",
       " [1, 3, 12, 6, 30, 4, 31, 32, 33, 2, 16, 1, 34, 6, 35, 4],\n",
       " [1, 3, 12, 6, 30, 4, 31, 32, 33, 2, 16, 1, 34, 6, 35, 4, 17],\n",
       " [1, 3, 12, 6, 30, 4, 31, 32, 33, 2, 16, 1, 34, 6, 35, 4, 17, 36],\n",
       " [1, 3, 12, 6, 30, 4, 31, 32, 33, 2, 16, 1, 34, 6, 35, 4, 17, 36, 13],\n",
       " [1, 3, 12, 6, 30, 4, 31, 32, 33, 2, 16, 1, 34, 6, 35, 4, 17, 36, 13, 37],\n",
       " [1, 3, 12, 6, 30, 4, 31, 32, 33, 2, 16, 1, 34, 6, 35, 4, 17, 36, 13, 37, 38],\n",
       " [1,\n",
       "  3,\n",
       "  12,\n",
       "  6,\n",
       "  30,\n",
       "  4,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  2,\n",
       "  16,\n",
       "  1,\n",
       "  34,\n",
       "  6,\n",
       "  35,\n",
       "  4,\n",
       "  17,\n",
       "  36,\n",
       "  13,\n",
       "  37,\n",
       "  38,\n",
       "  2],\n",
       " [1,\n",
       "  3,\n",
       "  12,\n",
       "  6,\n",
       "  30,\n",
       "  4,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  2,\n",
       "  16,\n",
       "  1,\n",
       "  34,\n",
       "  6,\n",
       "  35,\n",
       "  4,\n",
       "  17,\n",
       "  36,\n",
       "  13,\n",
       "  37,\n",
       "  38,\n",
       "  2,\n",
       "  39],\n",
       " [1,\n",
       "  3,\n",
       "  12,\n",
       "  6,\n",
       "  30,\n",
       "  4,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  2,\n",
       "  16,\n",
       "  1,\n",
       "  34,\n",
       "  6,\n",
       "  35,\n",
       "  4,\n",
       "  17,\n",
       "  36,\n",
       "  13,\n",
       "  37,\n",
       "  38,\n",
       "  2,\n",
       "  39,\n",
       "  40],\n",
       " [1,\n",
       "  3,\n",
       "  12,\n",
       "  6,\n",
       "  30,\n",
       "  4,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  2,\n",
       "  16,\n",
       "  1,\n",
       "  34,\n",
       "  6,\n",
       "  35,\n",
       "  4,\n",
       "  17,\n",
       "  36,\n",
       "  13,\n",
       "  37,\n",
       "  38,\n",
       "  2,\n",
       "  39,\n",
       "  40,\n",
       "  18],\n",
       " [1, 3],\n",
       " [1, 3, 41],\n",
       " [1, 3, 41, 42],\n",
       " [1, 3, 41, 42, 43],\n",
       " [1, 3, 41, 42, 43, 2],\n",
       " [1, 3, 41, 42, 43, 2, 44],\n",
       " [1, 3, 41, 42, 43, 2, 44, 45],\n",
       " [1, 3, 41, 42, 43, 2, 44, 45, 46],\n",
       " [1, 3, 41, 42, 43, 2, 44, 45, 46, 19],\n",
       " [1, 3, 41, 42, 43, 2, 44, 45, 46, 19, 47],\n",
       " [1, 3, 41, 42, 43, 2, 44, 45, 46, 19, 47, 8],\n",
       " [1, 3, 41, 42, 43, 2, 44, 45, 46, 19, 47, 8, 20],\n",
       " [1, 3, 41, 42, 43, 2, 44, 45, 46, 19, 47, 8, 20, 4],\n",
       " [1, 3, 41, 42, 43, 2, 44, 45, 46, 19, 47, 8, 20, 4, 48],\n",
       " [1, 3, 41, 42, 43, 2, 44, 45, 46, 19, 47, 8, 20, 4, 48, 2],\n",
       " [1, 3, 41, 42, 43, 2, 44, 45, 46, 19, 47, 8, 20, 4, 48, 2, 12],\n",
       " [1, 3, 41, 42, 43, 2, 44, 45, 46, 19, 47, 8, 20, 4, 48, 2, 12, 49],\n",
       " [1, 3, 41, 42, 43, 2, 44, 45, 46, 19, 47, 8, 20, 4, 48, 2, 12, 49, 7],\n",
       " [1, 3, 41, 42, 43, 2, 44, 45, 46, 19, 47, 8, 20, 4, 48, 2, 12, 49, 7, 50],\n",
       " [1, 3, 41, 42, 43, 2, 44, 45, 46, 19, 47, 8, 20, 4, 48, 2, 12, 49, 7, 50, 9],\n",
       " [1,\n",
       "  3,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  2,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  19,\n",
       "  47,\n",
       "  8,\n",
       "  20,\n",
       "  4,\n",
       "  48,\n",
       "  2,\n",
       "  12,\n",
       "  49,\n",
       "  7,\n",
       "  50,\n",
       "  9,\n",
       "  21],\n",
       " [1,\n",
       "  3,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  2,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  19,\n",
       "  47,\n",
       "  8,\n",
       "  20,\n",
       "  4,\n",
       "  48,\n",
       "  2,\n",
       "  12,\n",
       "  49,\n",
       "  7,\n",
       "  50,\n",
       "  9,\n",
       "  21,\n",
       "  2],\n",
       " [1,\n",
       "  3,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  2,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  19,\n",
       "  47,\n",
       "  8,\n",
       "  20,\n",
       "  4,\n",
       "  48,\n",
       "  2,\n",
       "  12,\n",
       "  49,\n",
       "  7,\n",
       "  50,\n",
       "  9,\n",
       "  21,\n",
       "  2,\n",
       "  51],\n",
       " [1,\n",
       "  3,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  2,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  19,\n",
       "  47,\n",
       "  8,\n",
       "  20,\n",
       "  4,\n",
       "  48,\n",
       "  2,\n",
       "  12,\n",
       "  49,\n",
       "  7,\n",
       "  50,\n",
       "  9,\n",
       "  21,\n",
       "  2,\n",
       "  51,\n",
       "  21],\n",
       " [1,\n",
       "  3,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  2,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  19,\n",
       "  47,\n",
       "  8,\n",
       "  20,\n",
       "  4,\n",
       "  48,\n",
       "  2,\n",
       "  12,\n",
       "  49,\n",
       "  7,\n",
       "  50,\n",
       "  9,\n",
       "  21,\n",
       "  2,\n",
       "  51,\n",
       "  21,\n",
       "  52],\n",
       " [7, 53],\n",
       " [7, 53, 9],\n",
       " [7, 53, 9, 54],\n",
       " [7, 53, 9, 54, 1],\n",
       " [7, 53, 9, 54, 1, 3],\n",
       " [7, 53, 9, 54, 1, 3, 55],\n",
       " [7, 53, 9, 54, 1, 3, 55, 8],\n",
       " [7, 53, 9, 54, 1, 3, 55, 8, 56],\n",
       " [7, 53, 9, 54, 1, 3, 55, 8, 56, 7],\n",
       " [7, 53, 9, 54, 1, 3, 55, 8, 56, 7, 18],\n",
       " [7, 53, 9, 54, 1, 3, 55, 8, 56, 7, 18, 57],\n",
       " [7, 53, 9, 54, 1, 3, 55, 8, 56, 7, 18, 57, 22],\n",
       " [7, 53, 9, 54, 1, 3, 55, 8, 56, 7, 18, 57, 22, 58],\n",
       " [7, 53, 9, 54, 1, 3, 55, 8, 56, 7, 18, 57, 22, 58, 2],\n",
       " [7, 53, 9, 54, 1, 3, 55, 8, 56, 7, 18, 57, 22, 58, 2, 59],\n",
       " [7, 53, 9, 54, 1, 3, 55, 8, 56, 7, 18, 57, 22, 58, 2, 59, 60],\n",
       " [7, 53, 9, 54, 1, 3, 55, 8, 56, 7, 18, 57, 22, 58, 2, 59, 60, 61],\n",
       " [7, 53, 9, 54, 1, 3, 55, 8, 56, 7, 18, 57, 22, 58, 2, 59, 60, 61, 22],\n",
       " [7, 53, 9, 54, 1, 3, 55, 8, 56, 7, 18, 57, 22, 58, 2, 59, 60, 61, 22, 62],\n",
       " [1, 63],\n",
       " [1, 63, 12],\n",
       " [1, 63, 12, 8],\n",
       " [1, 63, 12, 8, 64],\n",
       " [1, 63, 12, 8, 64, 1],\n",
       " [1, 63, 12, 8, 64, 1, 3],\n",
       " [1, 63, 12, 8, 64, 1, 3, 65],\n",
       " [1, 63, 12, 8, 64, 1, 3, 65, 23],\n",
       " [1, 63, 12, 8, 64, 1, 3, 65, 23, 10],\n",
       " [1, 63, 12, 8, 64, 1, 3, 65, 23, 10, 5],\n",
       " [1, 63, 12, 8, 64, 1, 3, 65, 23, 10, 5, 11],\n",
       " [1, 63, 12, 8, 64, 1, 3, 65, 23, 10, 5, 11, 16],\n",
       " [1, 63, 12, 8, 64, 1, 3, 65, 23, 10, 5, 11, 16, 2],\n",
       " [1, 63, 12, 8, 64, 1, 3, 65, 23, 10, 5, 11, 16, 2, 66],\n",
       " [1, 63, 12, 8, 64, 1, 3, 65, 23, 10, 5, 11, 16, 2, 66, 67],\n",
       " [1, 63, 12, 8, 64, 1, 3, 65, 23, 10, 5, 11, 16, 2, 66, 67, 24],\n",
       " [1, 63, 12, 8, 64, 1, 3, 65, 23, 10, 5, 11, 16, 2, 66, 67, 24, 14],\n",
       " [1, 63, 12, 8, 64, 1, 3, 65, 23, 10, 5, 11, 16, 2, 66, 67, 24, 14, 68],\n",
       " [1, 63, 12, 8, 64, 1, 3, 65, 23, 10, 5, 11, 16, 2, 66, 67, 24, 14, 68, 69],\n",
       " [1,\n",
       "  63,\n",
       "  12,\n",
       "  8,\n",
       "  64,\n",
       "  1,\n",
       "  3,\n",
       "  65,\n",
       "  23,\n",
       "  10,\n",
       "  5,\n",
       "  11,\n",
       "  16,\n",
       "  2,\n",
       "  66,\n",
       "  67,\n",
       "  24,\n",
       "  14,\n",
       "  68,\n",
       "  69,\n",
       "  70],\n",
       " [1,\n",
       "  63,\n",
       "  12,\n",
       "  8,\n",
       "  64,\n",
       "  1,\n",
       "  3,\n",
       "  65,\n",
       "  23,\n",
       "  10,\n",
       "  5,\n",
       "  11,\n",
       "  16,\n",
       "  2,\n",
       "  66,\n",
       "  67,\n",
       "  24,\n",
       "  14,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  25],\n",
       " [1,\n",
       "  63,\n",
       "  12,\n",
       "  8,\n",
       "  64,\n",
       "  1,\n",
       "  3,\n",
       "  65,\n",
       "  23,\n",
       "  10,\n",
       "  5,\n",
       "  11,\n",
       "  16,\n",
       "  2,\n",
       "  66,\n",
       "  67,\n",
       "  24,\n",
       "  14,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  25,\n",
       "  71],\n",
       " [1,\n",
       "  63,\n",
       "  12,\n",
       "  8,\n",
       "  64,\n",
       "  1,\n",
       "  3,\n",
       "  65,\n",
       "  23,\n",
       "  10,\n",
       "  5,\n",
       "  11,\n",
       "  16,\n",
       "  2,\n",
       "  66,\n",
       "  67,\n",
       "  24,\n",
       "  14,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  25,\n",
       "  71,\n",
       "  15],\n",
       " [1,\n",
       "  63,\n",
       "  12,\n",
       "  8,\n",
       "  64,\n",
       "  1,\n",
       "  3,\n",
       "  65,\n",
       "  23,\n",
       "  10,\n",
       "  5,\n",
       "  11,\n",
       "  16,\n",
       "  2,\n",
       "  66,\n",
       "  67,\n",
       "  24,\n",
       "  14,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  25,\n",
       "  71,\n",
       "  15,\n",
       "  9],\n",
       " [1,\n",
       "  63,\n",
       "  12,\n",
       "  8,\n",
       "  64,\n",
       "  1,\n",
       "  3,\n",
       "  65,\n",
       "  23,\n",
       "  10,\n",
       "  5,\n",
       "  11,\n",
       "  16,\n",
       "  2,\n",
       "  66,\n",
       "  67,\n",
       "  24,\n",
       "  14,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  25,\n",
       "  71,\n",
       "  15,\n",
       "  9,\n",
       "  72],\n",
       " [1,\n",
       "  63,\n",
       "  12,\n",
       "  8,\n",
       "  64,\n",
       "  1,\n",
       "  3,\n",
       "  65,\n",
       "  23,\n",
       "  10,\n",
       "  5,\n",
       "  11,\n",
       "  16,\n",
       "  2,\n",
       "  66,\n",
       "  67,\n",
       "  24,\n",
       "  14,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  25,\n",
       "  71,\n",
       "  15,\n",
       "  9,\n",
       "  72,\n",
       "  73],\n",
       " [1,\n",
       "  63,\n",
       "  12,\n",
       "  8,\n",
       "  64,\n",
       "  1,\n",
       "  3,\n",
       "  65,\n",
       "  23,\n",
       "  10,\n",
       "  5,\n",
       "  11,\n",
       "  16,\n",
       "  2,\n",
       "  66,\n",
       "  67,\n",
       "  24,\n",
       "  14,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  25,\n",
       "  71,\n",
       "  15,\n",
       "  9,\n",
       "  72,\n",
       "  73,\n",
       "  1],\n",
       " [1,\n",
       "  63,\n",
       "  12,\n",
       "  8,\n",
       "  64,\n",
       "  1,\n",
       "  3,\n",
       "  65,\n",
       "  23,\n",
       "  10,\n",
       "  5,\n",
       "  11,\n",
       "  16,\n",
       "  2,\n",
       "  66,\n",
       "  67,\n",
       "  24,\n",
       "  14,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  25,\n",
       "  71,\n",
       "  15,\n",
       "  9,\n",
       "  72,\n",
       "  73,\n",
       "  1,\n",
       "  3],\n",
       " [1,\n",
       "  63,\n",
       "  12,\n",
       "  8,\n",
       "  64,\n",
       "  1,\n",
       "  3,\n",
       "  65,\n",
       "  23,\n",
       "  10,\n",
       "  5,\n",
       "  11,\n",
       "  16,\n",
       "  2,\n",
       "  66,\n",
       "  67,\n",
       "  24,\n",
       "  14,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  25,\n",
       "  71,\n",
       "  15,\n",
       "  9,\n",
       "  72,\n",
       "  73,\n",
       "  1,\n",
       "  3,\n",
       "  23],\n",
       " [1,\n",
       "  63,\n",
       "  12,\n",
       "  8,\n",
       "  64,\n",
       "  1,\n",
       "  3,\n",
       "  65,\n",
       "  23,\n",
       "  10,\n",
       "  5,\n",
       "  11,\n",
       "  16,\n",
       "  2,\n",
       "  66,\n",
       "  67,\n",
       "  24,\n",
       "  14,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  25,\n",
       "  71,\n",
       "  15,\n",
       "  9,\n",
       "  72,\n",
       "  73,\n",
       "  1,\n",
       "  3,\n",
       "  23,\n",
       "  74],\n",
       " [1,\n",
       "  63,\n",
       "  12,\n",
       "  8,\n",
       "  64,\n",
       "  1,\n",
       "  3,\n",
       "  65,\n",
       "  23,\n",
       "  10,\n",
       "  5,\n",
       "  11,\n",
       "  16,\n",
       "  2,\n",
       "  66,\n",
       "  67,\n",
       "  24,\n",
       "  14,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  25,\n",
       "  71,\n",
       "  15,\n",
       "  9,\n",
       "  72,\n",
       "  73,\n",
       "  1,\n",
       "  3,\n",
       "  23,\n",
       "  74,\n",
       "  75],\n",
       " [1,\n",
       "  63,\n",
       "  12,\n",
       "  8,\n",
       "  64,\n",
       "  1,\n",
       "  3,\n",
       "  65,\n",
       "  23,\n",
       "  10,\n",
       "  5,\n",
       "  11,\n",
       "  16,\n",
       "  2,\n",
       "  66,\n",
       "  67,\n",
       "  24,\n",
       "  14,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  25,\n",
       "  71,\n",
       "  15,\n",
       "  9,\n",
       "  72,\n",
       "  73,\n",
       "  1,\n",
       "  3,\n",
       "  23,\n",
       "  74,\n",
       "  75,\n",
       "  5],\n",
       " [1,\n",
       "  63,\n",
       "  12,\n",
       "  8,\n",
       "  64,\n",
       "  1,\n",
       "  3,\n",
       "  65,\n",
       "  23,\n",
       "  10,\n",
       "  5,\n",
       "  11,\n",
       "  16,\n",
       "  2,\n",
       "  66,\n",
       "  67,\n",
       "  24,\n",
       "  14,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  25,\n",
       "  71,\n",
       "  15,\n",
       "  9,\n",
       "  72,\n",
       "  73,\n",
       "  1,\n",
       "  3,\n",
       "  23,\n",
       "  74,\n",
       "  75,\n",
       "  5,\n",
       "  76],\n",
       " [1,\n",
       "  63,\n",
       "  12,\n",
       "  8,\n",
       "  64,\n",
       "  1,\n",
       "  3,\n",
       "  65,\n",
       "  23,\n",
       "  10,\n",
       "  5,\n",
       "  11,\n",
       "  16,\n",
       "  2,\n",
       "  66,\n",
       "  67,\n",
       "  24,\n",
       "  14,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  25,\n",
       "  71,\n",
       "  15,\n",
       "  9,\n",
       "  72,\n",
       "  73,\n",
       "  1,\n",
       "  3,\n",
       "  23,\n",
       "  74,\n",
       "  75,\n",
       "  5,\n",
       "  76,\n",
       "  77],\n",
       " [1,\n",
       "  63,\n",
       "  12,\n",
       "  8,\n",
       "  64,\n",
       "  1,\n",
       "  3,\n",
       "  65,\n",
       "  23,\n",
       "  10,\n",
       "  5,\n",
       "  11,\n",
       "  16,\n",
       "  2,\n",
       "  66,\n",
       "  67,\n",
       "  24,\n",
       "  14,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  25,\n",
       "  71,\n",
       "  15,\n",
       "  9,\n",
       "  72,\n",
       "  73,\n",
       "  1,\n",
       "  3,\n",
       "  23,\n",
       "  74,\n",
       "  75,\n",
       "  5,\n",
       "  76,\n",
       "  77,\n",
       "  78],\n",
       " [1,\n",
       "  63,\n",
       "  12,\n",
       "  8,\n",
       "  64,\n",
       "  1,\n",
       "  3,\n",
       "  65,\n",
       "  23,\n",
       "  10,\n",
       "  5,\n",
       "  11,\n",
       "  16,\n",
       "  2,\n",
       "  66,\n",
       "  67,\n",
       "  24,\n",
       "  14,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  25,\n",
       "  71,\n",
       "  15,\n",
       "  9,\n",
       "  72,\n",
       "  73,\n",
       "  1,\n",
       "  3,\n",
       "  23,\n",
       "  74,\n",
       "  75,\n",
       "  5,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  5],\n",
       " [1,\n",
       "  63,\n",
       "  12,\n",
       "  8,\n",
       "  64,\n",
       "  1,\n",
       "  3,\n",
       "  65,\n",
       "  23,\n",
       "  10,\n",
       "  5,\n",
       "  11,\n",
       "  16,\n",
       "  2,\n",
       "  66,\n",
       "  67,\n",
       "  24,\n",
       "  14,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  25,\n",
       "  71,\n",
       "  15,\n",
       "  9,\n",
       "  72,\n",
       "  73,\n",
       "  1,\n",
       "  3,\n",
       "  23,\n",
       "  74,\n",
       "  75,\n",
       "  5,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  5,\n",
       "  9],\n",
       " [1,\n",
       "  63,\n",
       "  12,\n",
       "  8,\n",
       "  64,\n",
       "  1,\n",
       "  3,\n",
       "  65,\n",
       "  23,\n",
       "  10,\n",
       "  5,\n",
       "  11,\n",
       "  16,\n",
       "  2,\n",
       "  66,\n",
       "  67,\n",
       "  24,\n",
       "  14,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  25,\n",
       "  71,\n",
       "  15,\n",
       "  9,\n",
       "  72,\n",
       "  73,\n",
       "  1,\n",
       "  3,\n",
       "  23,\n",
       "  74,\n",
       "  75,\n",
       "  5,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  5,\n",
       "  9,\n",
       "  13],\n",
       " [7, 11],\n",
       " [7, 11, 79],\n",
       " [7, 11, 79, 1],\n",
       " [7, 11, 79, 1, 3],\n",
       " [7, 11, 79, 1, 3, 80],\n",
       " [7, 11, 79, 1, 3, 80, 81],\n",
       " [7, 11, 79, 1, 3, 80, 81, 82],\n",
       " [7, 11, 79, 1, 3, 80, 81, 82, 83],\n",
       " [7, 11, 79, 1, 3, 80, 81, 82, 83, 25],\n",
       " [7, 11, 79, 1, 3, 80, 81, 82, 83, 25, 84],\n",
       " [7, 11, 79, 1, 3, 80, 81, 82, 83, 25, 84, 85],\n",
       " [7, 11, 79, 1, 3, 80, 81, 82, 83, 25, 84, 85, 1],\n",
       " [7, 11, 79, 1, 3, 80, 81, 82, 83, 25, 84, 85, 1, 3],\n",
       " [7, 11, 79, 1, 3, 80, 81, 82, 83, 25, 84, 85, 1, 3, 26],\n",
       " [7, 11, 79, 1, 3, 80, 81, 82, 83, 25, 84, 85, 1, 3, 26, 2],\n",
       " [7, 11, 79, 1, 3, 80, 81, 82, 83, 25, 84, 85, 1, 3, 26, 2, 86],\n",
       " [7, 11, 79, 1, 3, 80, 81, 82, 83, 25, 84, 85, 1, 3, 26, 2, 86, 1],\n",
       " [7, 11, 79, 1, 3, 80, 81, 82, 83, 25, 84, 85, 1, 3, 26, 2, 86, 1, 3],\n",
       " [7, 11, 79, 1, 3, 80, 81, 82, 83, 25, 84, 85, 1, 3, 26, 2, 86, 1, 3, 27],\n",
       " [26, 10],\n",
       " [26, 10, 5],\n",
       " [26, 10, 5, 17],\n",
       " [26, 10, 5, 17, 87],\n",
       " [26, 10, 5, 17, 87, 88],\n",
       " [26, 10, 5, 17, 87, 88, 7],\n",
       " [26, 10, 5, 17, 87, 88, 7, 6],\n",
       " [26, 10, 5, 17, 87, 88, 7, 6, 1],\n",
       " [26, 10, 5, 17, 87, 88, 7, 6, 1, 15],\n",
       " [26, 10, 5, 17, 87, 88, 7, 6, 1, 15, 27],\n",
       " [26, 10, 5, 17, 87, 88, 7, 6, 1, 15, 27, 10],\n",
       " [26, 10, 5, 17, 87, 88, 7, 6, 1, 15, 27, 10, 5],\n",
       " [26, 10, 5, 17, 87, 88, 7, 6, 1, 15, 27, 10, 5, 89],\n",
       " [26, 10, 5, 17, 87, 88, 7, 6, 1, 15, 27, 10, 5, 89, 28],\n",
       " [26, 10, 5, 17, 87, 88, 7, 6, 1, 15, 27, 10, 5, 89, 28, 90],\n",
       " [26, 10, 5, 17, 87, 88, 7, 6, 1, 15, 27, 10, 5, 89, 28, 90, 91],\n",
       " [26, 10, 5, 17, 87, 88, 7, 6, 1, 15, 27, 10, 5, 89, 28, 90, 91, 92],\n",
       " [14, 29],\n",
       " [14, 29, 10],\n",
       " [14, 29, 10, 5],\n",
       " [14, 29, 10, 5, 6],\n",
       " [14, 29, 10, 5, 6, 93],\n",
       " [14, 29, 10, 5, 6, 93, 4],\n",
       " [14, 29, 10, 5, 6, 93, 4, 11],\n",
       " [14, 29, 10, 5, 6, 93, 4, 11, 94],\n",
       " [14, 29, 10, 5, 6, 93, 4, 11, 94, 24],\n",
       " [14, 29, 10, 5, 6, 93, 4, 11, 94, 24, 14],\n",
       " [14, 29, 10, 5, 6, 93, 4, 11, 94, 24, 14, 95],\n",
       " [14, 29, 10, 5, 6, 93, 4, 11, 94, 24, 14, 95, 28],\n",
       " [14, 29, 10, 5, 6, 93, 4, 11, 94, 24, 14, 95, 28, 96],\n",
       " [14, 29, 10, 5, 6, 93, 4, 11, 94, 24, 14, 95, 28, 96, 15],\n",
       " [14, 29, 10, 5, 6, 93, 4, 11, 94, 24, 14, 95, 28, 96, 15, 97],\n",
       " [14, 29, 10, 5, 6, 93, 4, 11, 94, 24, 14, 95, 28, 96, 15, 97, 29],\n",
       " [14, 29, 10, 5, 6, 93, 4, 11, 94, 24, 14, 95, 28, 96, 15, 97, 29, 98],\n",
       " [14, 29, 10, 5, 6, 93, 4, 11, 94, 24, 14, 95, 28, 96, 15, 97, 29, 98, 11],\n",
       " [14, 29, 10, 5, 6, 93, 4, 11, 94, 24, 14, 95, 28, 96, 15, 97, 29, 98, 11, 99],\n",
       " [14,\n",
       "  29,\n",
       "  10,\n",
       "  5,\n",
       "  6,\n",
       "  93,\n",
       "  4,\n",
       "  11,\n",
       "  94,\n",
       "  24,\n",
       "  14,\n",
       "  95,\n",
       "  28,\n",
       "  96,\n",
       "  15,\n",
       "  97,\n",
       "  29,\n",
       "  98,\n",
       "  11,\n",
       "  99,\n",
       "  2],\n",
       " [14,\n",
       "  29,\n",
       "  10,\n",
       "  5,\n",
       "  6,\n",
       "  93,\n",
       "  4,\n",
       "  11,\n",
       "  94,\n",
       "  24,\n",
       "  14,\n",
       "  95,\n",
       "  28,\n",
       "  96,\n",
       "  15,\n",
       "  97,\n",
       "  29,\n",
       "  98,\n",
       "  11,\n",
       "  99,\n",
       "  2,\n",
       "  100],\n",
       " [14,\n",
       "  29,\n",
       "  10,\n",
       "  5,\n",
       "  6,\n",
       "  93,\n",
       "  4,\n",
       "  11,\n",
       "  94,\n",
       "  24,\n",
       "  14,\n",
       "  95,\n",
       "  28,\n",
       "  96,\n",
       "  15,\n",
       "  97,\n",
       "  29,\n",
       "  98,\n",
       "  11,\n",
       "  99,\n",
       "  2,\n",
       "  100,\n",
       "  19],\n",
       " [14,\n",
       "  29,\n",
       "  10,\n",
       "  5,\n",
       "  6,\n",
       "  93,\n",
       "  4,\n",
       "  11,\n",
       "  94,\n",
       "  24,\n",
       "  14,\n",
       "  95,\n",
       "  28,\n",
       "  96,\n",
       "  15,\n",
       "  97,\n",
       "  29,\n",
       "  98,\n",
       "  11,\n",
       "  99,\n",
       "  2,\n",
       "  100,\n",
       "  19,\n",
       "  101],\n",
       " [14,\n",
       "  29,\n",
       "  10,\n",
       "  5,\n",
       "  6,\n",
       "  93,\n",
       "  4,\n",
       "  11,\n",
       "  94,\n",
       "  24,\n",
       "  14,\n",
       "  95,\n",
       "  28,\n",
       "  96,\n",
       "  15,\n",
       "  97,\n",
       "  29,\n",
       "  98,\n",
       "  11,\n",
       "  99,\n",
       "  2,\n",
       "  100,\n",
       "  19,\n",
       "  101,\n",
       "  102],\n",
       " [14,\n",
       "  29,\n",
       "  10,\n",
       "  5,\n",
       "  6,\n",
       "  93,\n",
       "  4,\n",
       "  11,\n",
       "  94,\n",
       "  24,\n",
       "  14,\n",
       "  95,\n",
       "  28,\n",
       "  96,\n",
       "  15,\n",
       "  97,\n",
       "  29,\n",
       "  98,\n",
       "  11,\n",
       "  99,\n",
       "  2,\n",
       "  100,\n",
       "  19,\n",
       "  101,\n",
       "  102,\n",
       "  2],\n",
       " [14,\n",
       "  29,\n",
       "  10,\n",
       "  5,\n",
       "  6,\n",
       "  93,\n",
       "  4,\n",
       "  11,\n",
       "  94,\n",
       "  24,\n",
       "  14,\n",
       "  95,\n",
       "  28,\n",
       "  96,\n",
       "  15,\n",
       "  97,\n",
       "  29,\n",
       "  98,\n",
       "  11,\n",
       "  99,\n",
       "  2,\n",
       "  100,\n",
       "  19,\n",
       "  101,\n",
       "  102,\n",
       "  2,\n",
       "  103],\n",
       " [14,\n",
       "  29,\n",
       "  10,\n",
       "  5,\n",
       "  6,\n",
       "  93,\n",
       "  4,\n",
       "  11,\n",
       "  94,\n",
       "  24,\n",
       "  14,\n",
       "  95,\n",
       "  28,\n",
       "  96,\n",
       "  15,\n",
       "  97,\n",
       "  29,\n",
       "  98,\n",
       "  11,\n",
       "  99,\n",
       "  2,\n",
       "  100,\n",
       "  19,\n",
       "  101,\n",
       "  102,\n",
       "  2,\n",
       "  103,\n",
       "  13],\n",
       " [14,\n",
       "  29,\n",
       "  10,\n",
       "  5,\n",
       "  6,\n",
       "  93,\n",
       "  4,\n",
       "  11,\n",
       "  94,\n",
       "  24,\n",
       "  14,\n",
       "  95,\n",
       "  28,\n",
       "  96,\n",
       "  15,\n",
       "  97,\n",
       "  29,\n",
       "  98,\n",
       "  11,\n",
       "  99,\n",
       "  2,\n",
       "  100,\n",
       "  19,\n",
       "  101,\n",
       "  102,\n",
       "  2,\n",
       "  103,\n",
       "  13,\n",
       "  104],\n",
       " [14,\n",
       "  29,\n",
       "  10,\n",
       "  5,\n",
       "  6,\n",
       "  93,\n",
       "  4,\n",
       "  11,\n",
       "  94,\n",
       "  24,\n",
       "  14,\n",
       "  95,\n",
       "  28,\n",
       "  96,\n",
       "  15,\n",
       "  97,\n",
       "  29,\n",
       "  98,\n",
       "  11,\n",
       "  99,\n",
       "  2,\n",
       "  100,\n",
       "  19,\n",
       "  101,\n",
       "  102,\n",
       "  2,\n",
       "  103,\n",
       "  13,\n",
       "  104,\n",
       "  105],\n",
       " [14,\n",
       "  29,\n",
       "  10,\n",
       "  5,\n",
       "  6,\n",
       "  93,\n",
       "  4,\n",
       "  11,\n",
       "  94,\n",
       "  24,\n",
       "  14,\n",
       "  95,\n",
       "  28,\n",
       "  96,\n",
       "  15,\n",
       "  97,\n",
       "  29,\n",
       "  98,\n",
       "  11,\n",
       "  99,\n",
       "  2,\n",
       "  100,\n",
       "  19,\n",
       "  101,\n",
       "  102,\n",
       "  2,\n",
       "  103,\n",
       "  13,\n",
       "  104,\n",
       "  105,\n",
       "  106],\n",
       " [14,\n",
       "  29,\n",
       "  10,\n",
       "  5,\n",
       "  6,\n",
       "  93,\n",
       "  4,\n",
       "  11,\n",
       "  94,\n",
       "  24,\n",
       "  14,\n",
       "  95,\n",
       "  28,\n",
       "  96,\n",
       "  15,\n",
       "  97,\n",
       "  29,\n",
       "  98,\n",
       "  11,\n",
       "  99,\n",
       "  2,\n",
       "  100,\n",
       "  19,\n",
       "  101,\n",
       "  102,\n",
       "  2,\n",
       "  103,\n",
       "  13,\n",
       "  104,\n",
       "  105,\n",
       "  106,\n",
       "  8],\n",
       " [14,\n",
       "  29,\n",
       "  10,\n",
       "  5,\n",
       "  6,\n",
       "  93,\n",
       "  4,\n",
       "  11,\n",
       "  94,\n",
       "  24,\n",
       "  14,\n",
       "  95,\n",
       "  28,\n",
       "  96,\n",
       "  15,\n",
       "  97,\n",
       "  29,\n",
       "  98,\n",
       "  11,\n",
       "  99,\n",
       "  2,\n",
       "  100,\n",
       "  19,\n",
       "  101,\n",
       "  102,\n",
       "  2,\n",
       "  103,\n",
       "  13,\n",
       "  104,\n",
       "  105,\n",
       "  106,\n",
       "  8,\n",
       "  20],\n",
       " [14,\n",
       "  29,\n",
       "  10,\n",
       "  5,\n",
       "  6,\n",
       "  93,\n",
       "  4,\n",
       "  11,\n",
       "  94,\n",
       "  24,\n",
       "  14,\n",
       "  95,\n",
       "  28,\n",
       "  96,\n",
       "  15,\n",
       "  97,\n",
       "  29,\n",
       "  98,\n",
       "  11,\n",
       "  99,\n",
       "  2,\n",
       "  100,\n",
       "  19,\n",
       "  101,\n",
       "  102,\n",
       "  2,\n",
       "  103,\n",
       "  13,\n",
       "  104,\n",
       "  105,\n",
       "  106,\n",
       "  8,\n",
       "  20,\n",
       "  4],\n",
       " [14,\n",
       "  29,\n",
       "  10,\n",
       "  5,\n",
       "  6,\n",
       "  93,\n",
       "  4,\n",
       "  11,\n",
       "  94,\n",
       "  24,\n",
       "  14,\n",
       "  95,\n",
       "  28,\n",
       "  96,\n",
       "  15,\n",
       "  97,\n",
       "  29,\n",
       "  98,\n",
       "  11,\n",
       "  99,\n",
       "  2,\n",
       "  100,\n",
       "  19,\n",
       "  101,\n",
       "  102,\n",
       "  2,\n",
       "  103,\n",
       "  13,\n",
       "  104,\n",
       "  105,\n",
       "  106,\n",
       "  8,\n",
       "  20,\n",
       "  4,\n",
       "  107],\n",
       " [14,\n",
       "  29,\n",
       "  10,\n",
       "  5,\n",
       "  6,\n",
       "  93,\n",
       "  4,\n",
       "  11,\n",
       "  94,\n",
       "  24,\n",
       "  14,\n",
       "  95,\n",
       "  28,\n",
       "  96,\n",
       "  15,\n",
       "  97,\n",
       "  29,\n",
       "  98,\n",
       "  11,\n",
       "  99,\n",
       "  2,\n",
       "  100,\n",
       "  19,\n",
       "  101,\n",
       "  102,\n",
       "  2,\n",
       "  103,\n",
       "  13,\n",
       "  104,\n",
       "  105,\n",
       "  106,\n",
       "  8,\n",
       "  20,\n",
       "  4,\n",
       "  107,\n",
       "  1],\n",
       " [108, 4],\n",
       " [108, 4, 6],\n",
       " [108, 4, 6, 109],\n",
       " [108, 4, 6, 109, 110],\n",
       " [108, 4, 6, 109, 110, 111],\n",
       " [108, 4, 6, 109, 110, 111, 4],\n",
       " [108, 4, 6, 109, 110, 111, 4, 1],\n",
       " [108, 4, 6, 109, 110, 111, 4, 1, 3]]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a8e5d1c8-e55e-4237-8abc-35ef8ee026f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(x) for x in input_sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ac970b33-b34f-47c1-965e-3993caf03808",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(x) for x in input_sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1b1b7af5-b670-48a5-bd05-fe2d347617f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8aa0a2cf-d145-4e99-8fe5-275756caea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_input_sequenc = pad_sequences(input_sequence,maxlen=max_len,padding='pre') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "16557e31-0cc8-4d1c-a6a9-c0f3c5f275b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   1,   3],\n",
       "       [  0,   0,   0, ...,   1,   3,  12],\n",
       "       [  0,   0,   0, ...,   3,  12,   6],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 110, 111,   4],\n",
       "       [  0,   0,   0, ..., 111,   4,   1],\n",
       "       [  0,   0,   0, ...,   4,   1,   3]], shape=(185, 39), dtype=int32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_input_sequenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "80e8d6b6-0418-442e-825e-2d9f5fec7af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = padded_input_sequenc[:,:-1] \n",
    "y = padded_input_sequenc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "02b6045b-1716-4da0-a23b-18bf73049b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   0,   1],\n",
       "       [  0,   0,   0, ...,   0,   1,   3],\n",
       "       [  0,   0,   0, ...,   1,   3,  12],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 109, 110, 111],\n",
       "       [  0,   0,   0, ..., 110, 111,   4],\n",
       "       [  0,   0,   0, ..., 111,   4,   1]], shape=(185, 38), dtype=int32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "aad28b79-a85b-4d0f-b4e9-b097cedeed6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3,  12,   6,  30,   4,  31,  32,  33,   2,  16,   1,  34,   6,\n",
       "        35,   4,  17,  36,  13,  37,  38,   2,  39,  40,  18,   3,  41,\n",
       "        42,  43,   2,  44,  45,  46,  19,  47,   8,  20,   4,  48,   2,\n",
       "        12,  49,   7,  50,   9,  21,   2,  51,  21,  52,  53,   9,  54,\n",
       "         1,   3,  55,   8,  56,   7,  18,  57,  22,  58,   2,  59,  60,\n",
       "        61,  22,  62,  63,  12,   8,  64,   1,   3,  65,  23,  10,   5,\n",
       "        11,  16,   2,  66,  67,  24,  14,  68,  69,  70,  25,  71,  15,\n",
       "         9,  72,  73,   1,   3,  23,  74,  75,   5,  76,  77,  78,   5,\n",
       "         9,  13,  11,  79,   1,   3,  80,  81,  82,  83,  25,  84,  85,\n",
       "         1,   3,  26,   2,  86,   1,   3,  27,  10,   5,  17,  87,  88,\n",
       "         7,   6,   1,  15,  27,  10,   5,  89,  28,  90,  91,  92,  29,\n",
       "        10,   5,   6,  93,   4,  11,  94,  24,  14,  95,  28,  96,  15,\n",
       "        97,  29,  98,  11,  99,   2, 100,  19, 101, 102,   2, 103,  13,\n",
       "       104, 105, 106,   8,  20,   4, 107,   1,   4,   6, 109, 110, 111,\n",
       "         4,   1,   3], dtype=int32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5697d829-7ea9-408a-b5d2-dca9ea69ad65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 1,\n",
       " 'and': 2,\n",
       " 'analysis': 3,\n",
       " 'of': 4,\n",
       " 'on': 5,\n",
       " 'the': 6,\n",
       " 'in': 7,\n",
       " 'a': 8,\n",
       " 'business': 9,\n",
       " 'focuses': 10,\n",
       " 'statistical': 11,\n",
       " 'is': 12,\n",
       " 'information': 13,\n",
       " 'predictive': 14,\n",
       " 'while': 15,\n",
       " 'modeling': 16,\n",
       " 'discovering': 17,\n",
       " 'making': 18,\n",
       " 'techniques': 19,\n",
       " 'variety': 20,\n",
       " 'science': 21,\n",
       " 'more': 22,\n",
       " 'that': 23,\n",
       " 'for': 24,\n",
       " 'descriptive': 25,\n",
       " 'eda': 26,\n",
       " 'cda': 27,\n",
       " 'or': 28,\n",
       " 'analytics': 29,\n",
       " 'process': 30,\n",
       " 'inspecting': 31,\n",
       " 'cleansing': 32,\n",
       " 'transforming': 33,\n",
       " 'with': 34,\n",
       " 'goal': 35,\n",
       " 'useful': 36,\n",
       " 'informing': 37,\n",
       " 'conclusions': 38,\n",
       " 'supporting': 39,\n",
       " 'decision': 40,\n",
       " 'has': 41,\n",
       " 'multiple': 42,\n",
       " 'facets': 43,\n",
       " 'approaches': 44,\n",
       " 'encompassing': 45,\n",
       " 'diverse': 46,\n",
       " 'under': 47,\n",
       " 'names': 48,\n",
       " 'used': 49,\n",
       " 'different': 50,\n",
       " 'social': 51,\n",
       " 'domains': 52,\n",
       " \"today's\": 53,\n",
       " 'world': 54,\n",
       " 'plays': 55,\n",
       " 'role': 56,\n",
       " 'decisions': 57,\n",
       " 'scientific': 58,\n",
       " 'helping': 59,\n",
       " 'businesses': 60,\n",
       " 'operate': 61,\n",
       " 'effectively': 62,\n",
       " 'mining': 63,\n",
       " 'particular': 64,\n",
       " 'technique': 65,\n",
       " 'knowledge': 66,\n",
       " 'discovery': 67,\n",
       " 'rather': 68,\n",
       " 'than': 69,\n",
       " 'purely': 70,\n",
       " 'purposes': 71,\n",
       " 'intelligence': 72,\n",
       " 'covers': 73,\n",
       " 'relies': 74,\n",
       " 'heavily': 75,\n",
       " 'aggregation': 76,\n",
       " 'focusing': 77,\n",
       " 'mainly': 78,\n",
       " 'applications': 79,\n",
       " 'can': 80,\n",
       " 'be': 81,\n",
       " 'divided': 82,\n",
       " 'into': 83,\n",
       " 'statistics': 84,\n",
       " 'exploratory': 85,\n",
       " 'confirmatory': 86,\n",
       " 'new': 87,\n",
       " 'features': 88,\n",
       " 'confirming': 89,\n",
       " 'falsifying': 90,\n",
       " 'existing': 91,\n",
       " 'hypotheses': 92,\n",
       " 'application': 93,\n",
       " 'models': 94,\n",
       " 'forecasting': 95,\n",
       " 'classification': 96,\n",
       " 'text': 97,\n",
       " 'applies': 98,\n",
       " 'linguistic': 99,\n",
       " 'structural': 100,\n",
       " 'to': 101,\n",
       " 'extract': 102,\n",
       " 'classify': 103,\n",
       " 'from': 104,\n",
       " 'textual': 105,\n",
       " 'sources': 106,\n",
       " 'unstructured': 107,\n",
       " 'all': 108,\n",
       " 'above': 109,\n",
       " 'are': 110,\n",
       " 'varieties': 111}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1d673d91-07fc-4684-a70f-3d4ebf1d280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "44444593-d98d-40de-baee-cfe68c01cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=to_categorical(y,num_classes=112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "408d4e0a-98dd-467a-90dd-eca5e25cdaf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185, 112)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0e0fe150-ecda-4db8-810b-dd5c387b7bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185, 38)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66345858-e82f-4d93-9091-a7596d5f0eeb",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "df63f894-b181-4280-a111-85ee9bb4ed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "98d496ec-491f-47ab-88a0-5f42efc3a6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">180,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,912</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_14 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m150\u001b[0m)        │        \u001b[38;5;34m16,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_14 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m180,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m)            │        \u001b[38;5;34m16,912\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">214,312</span> (837.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m214,312\u001b[0m (837.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">214,312</span> (837.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m214,312\u001b[0m (837.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 150))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Build model with input shape (batch_size can be None)\n",
    "model.build(input_shape=(None, input_length))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "138d1723-2d36-43d2-90dd-7ebea87cdb48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185, 38)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "87306a7c-6a2b-4823-ad4f-9ef391c20e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185, 112)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bdaae850-b057-42b8-8294-a439a452c411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.0216 - loss: 4.7153   \n",
      "Epoch 2/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0595 - loss: 4.6592\n",
      "Epoch 3/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0378 - loss: 4.5254\n",
      "Epoch 4/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0595 - loss: 4.4200\n",
      "Epoch 5/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0757 - loss: 4.3507\n",
      "Epoch 6/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0703 - loss: 4.2985\n",
      "Epoch 7/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0811 - loss: 4.2455\n",
      "Epoch 8/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0973 - loss: 4.1663\n",
      "Epoch 9/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0811 - loss: 4.1063\n",
      "Epoch 10/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0919 - loss: 4.0368\n",
      "Epoch 11/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0973 - loss: 3.9544\n",
      "Epoch 12/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0973 - loss: 3.8679\n",
      "Epoch 13/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1135 - loss: 3.7725\n",
      "Epoch 14/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1189 - loss: 3.6613\n",
      "Epoch 15/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1514 - loss: 3.5489\n",
      "Epoch 16/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1838 - loss: 3.4397\n",
      "Epoch 17/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1622 - loss: 3.3021 \n",
      "Epoch 18/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1838 - loss: 3.1972\n",
      "Epoch 19/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2054 - loss: 3.0505\n",
      "Epoch 20/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2432 - loss: 2.9205\n",
      "Epoch 21/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2324 - loss: 2.7834\n",
      "Epoch 22/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2595 - loss: 2.6616\n",
      "Epoch 23/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2811 - loss: 2.5364\n",
      "Epoch 24/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3351 - loss: 2.4173\n",
      "Epoch 25/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3676 - loss: 2.3011\n",
      "Epoch 26/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3568 - loss: 2.2028\n",
      "Epoch 27/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4919 - loss: 2.1104\n",
      "Epoch 28/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5189 - loss: 2.0148\n",
      "Epoch 29/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5297 - loss: 1.9320\n",
      "Epoch 30/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5730 - loss: 1.8446\n",
      "Epoch 31/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6595 - loss: 1.7629\n",
      "Epoch 32/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6811 - loss: 1.6886\n",
      "Epoch 33/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7081 - loss: 1.6210\n",
      "Epoch 34/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7081 - loss: 1.5719\n",
      "Epoch 35/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7676 - loss: 1.4932\n",
      "Epoch 36/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7892 - loss: 1.4335\n",
      "Epoch 37/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8324 - loss: 1.3602\n",
      "Epoch 38/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8541 - loss: 1.3182\n",
      "Epoch 39/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8595 - loss: 1.2690\n",
      "Epoch 40/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9135 - loss: 1.2084\n",
      "Epoch 41/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9081 - loss: 1.1653\n",
      "Epoch 42/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9297 - loss: 1.1041\n",
      "Epoch 43/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9351 - loss: 1.0622\n",
      "Epoch 44/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9459 - loss: 1.0174\n",
      "Epoch 45/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9514 - loss: 0.9818\n",
      "Epoch 46/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9459 - loss: 0.9377\n",
      "Epoch 47/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9676 - loss: 0.9008\n",
      "Epoch 48/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9784 - loss: 0.8587\n",
      "Epoch 49/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9784 - loss: 0.8294\n",
      "Epoch 50/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9838 - loss: 0.7973 \n",
      "Epoch 51/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9838 - loss: 0.7639\n",
      "Epoch 52/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9838 - loss: 0.7377\n",
      "Epoch 53/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9838 - loss: 0.7161\n",
      "Epoch 54/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9784 - loss: 0.6849\n",
      "Epoch 55/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9838 - loss: 0.6541\n",
      "Epoch 56/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9838 - loss: 0.6295\n",
      "Epoch 57/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9838 - loss: 0.6018 \n",
      "Epoch 58/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9838 - loss: 0.5815\n",
      "Epoch 59/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9838 - loss: 0.5636\n",
      "Epoch 60/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9838 - loss: 0.5431\n",
      "Epoch 61/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9838 - loss: 0.5164\n",
      "Epoch 62/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9838 - loss: 0.4986 \n",
      "Epoch 63/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9838 - loss: 0.4779\n",
      "Epoch 64/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9838 - loss: 0.4603\n",
      "Epoch 65/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9838 - loss: 0.4458\n",
      "Epoch 66/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9838 - loss: 0.4262\n",
      "Epoch 67/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9838 - loss: 0.4083\n",
      "Epoch 68/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9784 - loss: 0.4044\n",
      "Epoch 69/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9730 - loss: 0.3920\n",
      "Epoch 70/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9838 - loss: 0.3717\n",
      "Epoch 71/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9838 - loss: 0.3587\n",
      "Epoch 72/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9838 - loss: 0.3428\n",
      "Epoch 73/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9838 - loss: 0.3299\n",
      "Epoch 74/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9784 - loss: 0.3197\n",
      "Epoch 75/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9784 - loss: 0.3101\n",
      "Epoch 76/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9838 - loss: 0.2990\n",
      "Epoch 77/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9838 - loss: 0.2883\n",
      "Epoch 78/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9838 - loss: 0.2788\n",
      "Epoch 79/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9838 - loss: 0.2701\n",
      "Epoch 80/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9838 - loss: 0.2609 \n",
      "Epoch 81/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9784 - loss: 0.2544\n",
      "Epoch 82/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9784 - loss: 0.2451\n",
      "Epoch 83/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9838 - loss: 0.2373\n",
      "Epoch 84/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9838 - loss: 0.2319\n",
      "Epoch 85/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9784 - loss: 0.2255\n",
      "Epoch 86/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9838 - loss: 0.2186\n",
      "Epoch 87/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9838 - loss: 0.2123 \n",
      "Epoch 88/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9838 - loss: 0.2061\n",
      "Epoch 89/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9784 - loss: 0.2005\n",
      "Epoch 90/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9784 - loss: 0.1950\n",
      "Epoch 91/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9784 - loss: 0.1897\n",
      "Epoch 92/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9838 - loss: 0.1856\n",
      "Epoch 93/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9784 - loss: 0.1803\n",
      "Epoch 94/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9838 - loss: 0.1755\n",
      "Epoch 95/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9838 - loss: 0.1707\n",
      "Epoch 96/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9784 - loss: 0.1677\n",
      "Epoch 97/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9784 - loss: 0.1634\n",
      "Epoch 98/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9784 - loss: 0.1592\n",
      "Epoch 99/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9838 - loss: 0.1559\n",
      "Epoch 100/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9838 - loss: 0.1524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a7d61d58a50>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce401276-462d-4f5b-b907-ca185d0a823e",
   "metadata": {},
   "source": [
    "## Testing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "678f4320-a4a8-4165-a8a9-da89ae011725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.79884719e-05, 4.01552825e-04, 2.39735848e-04, 5.57572639e-04,\n",
       "        3.93632352e-02, 2.67465394e-02, 7.10351095e-02, 6.86546904e-04,\n",
       "        1.48791145e-03, 1.14229377e-02, 8.34502205e-02, 1.45120934e-01,\n",
       "        1.16130523e-01, 9.42237384e-05, 8.62014640e-05, 1.87296318e-04,\n",
       "        6.91210662e-05, 8.82179476e-03, 1.69715422e-04, 1.45535250e-05,\n",
       "        2.68838194e-04, 9.48604647e-05, 9.78864409e-05, 1.00664317e-03,\n",
       "        4.84913064e-04, 3.60708538e-04, 1.10477326e-04, 6.65752566e-04,\n",
       "        4.06771396e-05, 1.38352349e-01, 1.69217389e-03, 7.12027017e-04,\n",
       "        2.69648939e-04, 1.50991560e-04, 1.89956809e-05, 3.58283636e-04,\n",
       "        1.33195908e-05, 1.86965081e-05, 2.82060191e-05, 1.97639911e-05,\n",
       "        1.00804900e-05, 1.89996690e-01, 1.61807239e-02, 3.77207034e-04,\n",
       "        5.39859284e-05, 1.46598813e-05, 1.83411466e-05, 1.02708045e-05,\n",
       "        1.17546384e-04, 1.04085018e-04, 5.98273982e-05, 3.66271488e-05,\n",
       "        4.83269287e-06, 9.60493013e-02, 3.29277827e-03, 5.03744581e-04,\n",
       "        5.51110097e-05, 3.11313961e-05, 1.75025867e-04, 1.25446422e-05,\n",
       "        3.02261160e-05, 6.76902782e-05, 3.04506084e-05, 1.14227170e-02,\n",
       "        8.75336875e-04, 5.86237002e-04, 2.78853058e-05, 1.16231888e-04,\n",
       "        6.09477247e-05, 6.36051409e-05, 2.08798534e-04, 7.13256086e-05,\n",
       "        1.71720807e-04, 1.52824010e-04, 1.93006548e-04, 1.67593214e-04,\n",
       "        6.66410924e-05, 2.62164016e-04, 9.28341353e-04, 4.53812815e-03,\n",
       "        2.82686856e-03, 3.72234790e-04, 8.69747950e-04, 1.76685848e-04,\n",
       "        1.60630094e-04, 1.39394891e-04, 3.56453456e-05, 6.68415916e-04,\n",
       "        4.41208133e-04, 5.44685827e-05, 5.59438740e-05, 3.14650388e-05,\n",
       "        3.70450607e-06, 9.24041029e-04, 2.00040100e-04, 2.62388523e-04,\n",
       "        1.10100467e-04, 7.00163248e-04, 1.59623421e-04, 1.58272145e-04,\n",
       "        6.32568335e-05, 1.21099429e-05, 3.33413846e-05, 7.11530447e-05,\n",
       "        5.80621272e-05, 1.24030528e-04, 1.36029601e-04, 6.11867945e-05,\n",
       "        7.95026790e-06, 6.21965947e-03, 2.76054814e-03, 4.08634404e-03]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2=\"analysis\" \n",
    "\n",
    "# Tokenization\n",
    "token_text =tokenizer.texts_to_sequences([text2])[0]\n",
    "\n",
    "# Padding \n",
    "padded_text=pad_sequences([token_text],maxlen=40,padding='pre') \n",
    "\n",
    "model.predict(padded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8a6f4a03-10a2-46e4-be07-0d58c3b00d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "pos=np.argmax(model.predict(padded_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "db5e6e42-3709-4b41-9625-66a047849498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 1,\n",
       " 'and': 2,\n",
       " 'analysis': 3,\n",
       " 'of': 4,\n",
       " 'on': 5,\n",
       " 'the': 6,\n",
       " 'in': 7,\n",
       " 'a': 8,\n",
       " 'business': 9,\n",
       " 'focuses': 10,\n",
       " 'statistical': 11,\n",
       " 'is': 12,\n",
       " 'information': 13,\n",
       " 'predictive': 14,\n",
       " 'while': 15,\n",
       " 'modeling': 16,\n",
       " 'discovering': 17,\n",
       " 'making': 18,\n",
       " 'techniques': 19,\n",
       " 'variety': 20,\n",
       " 'science': 21,\n",
       " 'more': 22,\n",
       " 'that': 23,\n",
       " 'for': 24,\n",
       " 'descriptive': 25,\n",
       " 'eda': 26,\n",
       " 'cda': 27,\n",
       " 'or': 28,\n",
       " 'analytics': 29,\n",
       " 'process': 30,\n",
       " 'inspecting': 31,\n",
       " 'cleansing': 32,\n",
       " 'transforming': 33,\n",
       " 'with': 34,\n",
       " 'goal': 35,\n",
       " 'useful': 36,\n",
       " 'informing': 37,\n",
       " 'conclusions': 38,\n",
       " 'supporting': 39,\n",
       " 'decision': 40,\n",
       " 'has': 41,\n",
       " 'multiple': 42,\n",
       " 'facets': 43,\n",
       " 'approaches': 44,\n",
       " 'encompassing': 45,\n",
       " 'diverse': 46,\n",
       " 'under': 47,\n",
       " 'names': 48,\n",
       " 'used': 49,\n",
       " 'different': 50,\n",
       " 'social': 51,\n",
       " 'domains': 52,\n",
       " \"today's\": 53,\n",
       " 'world': 54,\n",
       " 'plays': 55,\n",
       " 'role': 56,\n",
       " 'decisions': 57,\n",
       " 'scientific': 58,\n",
       " 'helping': 59,\n",
       " 'businesses': 60,\n",
       " 'operate': 61,\n",
       " 'effectively': 62,\n",
       " 'mining': 63,\n",
       " 'particular': 64,\n",
       " 'technique': 65,\n",
       " 'knowledge': 66,\n",
       " 'discovery': 67,\n",
       " 'rather': 68,\n",
       " 'than': 69,\n",
       " 'purely': 70,\n",
       " 'purposes': 71,\n",
       " 'intelligence': 72,\n",
       " 'covers': 73,\n",
       " 'relies': 74,\n",
       " 'heavily': 75,\n",
       " 'aggregation': 76,\n",
       " 'focusing': 77,\n",
       " 'mainly': 78,\n",
       " 'applications': 79,\n",
       " 'can': 80,\n",
       " 'be': 81,\n",
       " 'divided': 82,\n",
       " 'into': 83,\n",
       " 'statistics': 84,\n",
       " 'exploratory': 85,\n",
       " 'confirmatory': 86,\n",
       " 'new': 87,\n",
       " 'features': 88,\n",
       " 'confirming': 89,\n",
       " 'falsifying': 90,\n",
       " 'existing': 91,\n",
       " 'hypotheses': 92,\n",
       " 'application': 93,\n",
       " 'models': 94,\n",
       " 'forecasting': 95,\n",
       " 'classification': 96,\n",
       " 'text': 97,\n",
       " 'applies': 98,\n",
       " 'linguistic': 99,\n",
       " 'structural': 100,\n",
       " 'to': 101,\n",
       " 'extract': 102,\n",
       " 'classify': 103,\n",
       " 'from': 104,\n",
       " 'textual': 105,\n",
       " 'sources': 106,\n",
       " 'unstructured': 107,\n",
       " 'all': 108,\n",
       " 'above': 109,\n",
       " 'are': 110,\n",
       " 'varieties': 111}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "48e2841e-e0bd-4e05-a276-d9cc44894d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has\n"
     ]
    }
   ],
   "source": [
    "for word,index in tokenizer.word_index.items(): \n",
    "    if index==pos: \n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8e84e-a637-46c5-9850-b874ec515825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
