{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a28069ef-7d3b-457f-a6d2-243dbc15b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "text =\"\"\"Are you eager to break into the exciting world of data analytics? \n",
    "Whether you're a beginner or looking to level up your skills, \n",
    "mastering the right tools and resources can fast-track your journey to landing a high-paying data analytics job.\n",
    "In this blog, we’ll share a curated list of free,\n",
    "high-quality resources to help you build a strong foundation in data analytics and ace your next interview.\n",
    "Follow these steps, and you’ll be well on your way to a rewarding career!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c98d336-4f4e-4aba-84e0-d4c9725a6d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b8de40f-6e8d-4974-83c3-8ba24d564303",
   "metadata": {},
   "outputs": [],
   "source": [
    " # initiate the tokenizer\n",
    "tokenizer =Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dde2a13-0273-4b1f-b2e2-2b5e138e6504",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([text]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a201ed1-26ff-44ce-8928-a79652e24b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f499b6a5-5e8d-4b6d-929d-d7d48fae3142",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence=[]\n",
    "for sentence in text.split('\\n'): \n",
    "    tokenize_sentance = tokenizer.texts_to_sequences([sentence])[0]  \n",
    "    for i in range(1,len(tokenize_sentance)): \n",
    "        input_sequence.append(tokenize_sentance[:i+1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb58f2e2-f6d2-4db0-be49-efb3a31d18b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[13, 7],\n",
       " [13, 7, 14],\n",
       " [13, 7, 14, 1],\n",
       " [13, 7, 14, 1, 15],\n",
       " [13, 7, 14, 1, 15, 16],\n",
       " [13, 7, 14, 1, 15, 16, 8],\n",
       " [13, 7, 14, 1, 15, 16, 8, 17],\n",
       " [13, 7, 14, 1, 15, 16, 8, 17, 18],\n",
       " [13, 7, 14, 1, 15, 16, 8, 17, 18, 9],\n",
       " [13, 7, 14, 1, 15, 16, 8, 17, 18, 9, 4],\n",
       " [13, 7, 14, 1, 15, 16, 8, 17, 18, 9, 4, 5],\n",
       " [19, 20],\n",
       " [19, 20, 2],\n",
       " [19, 20, 2, 21],\n",
       " [19, 20, 2, 21, 22],\n",
       " [19, 20, 2, 21, 22, 23],\n",
       " [19, 20, 2, 21, 22, 23, 1],\n",
       " [19, 20, 2, 21, 22, 23, 1, 24],\n",
       " [19, 20, 2, 21, 22, 23, 1, 24, 25],\n",
       " [19, 20, 2, 21, 22, 23, 1, 24, 25, 3],\n",
       " [19, 20, 2, 21, 22, 23, 1, 24, 25, 3, 26],\n",
       " [27, 8],\n",
       " [27, 8, 28],\n",
       " [27, 8, 28, 29],\n",
       " [27, 8, 28, 29, 6],\n",
       " [27, 8, 28, 29, 6, 10],\n",
       " [27, 8, 28, 29, 6, 10, 30],\n",
       " [27, 8, 28, 29, 6, 10, 30, 31],\n",
       " [27, 8, 28, 29, 6, 10, 30, 31, 32],\n",
       " [27, 8, 28, 29, 6, 10, 30, 31, 32, 3],\n",
       " [27, 8, 28, 29, 6, 10, 30, 31, 32, 3, 33],\n",
       " [27, 8, 28, 29, 6, 10, 30, 31, 32, 3, 33, 1],\n",
       " [27, 8, 28, 29, 6, 10, 30, 31, 32, 3, 33, 1, 34],\n",
       " [27, 8, 28, 29, 6, 10, 30, 31, 32, 3, 33, 1, 34, 2],\n",
       " [27, 8, 28, 29, 6, 10, 30, 31, 32, 3, 33, 1, 34, 2, 11],\n",
       " [27, 8, 28, 29, 6, 10, 30, 31, 32, 3, 33, 1, 34, 2, 11, 35],\n",
       " [27, 8, 28, 29, 6, 10, 30, 31, 32, 3, 33, 1, 34, 2, 11, 35, 4],\n",
       " [27, 8, 28, 29, 6, 10, 30, 31, 32, 3, 33, 1, 34, 2, 11, 35, 4, 5],\n",
       " [27, 8, 28, 29, 6, 10, 30, 31, 32, 3, 33, 1, 34, 2, 11, 35, 4, 5, 36],\n",
       " [12, 37],\n",
       " [12, 37, 38],\n",
       " [12, 37, 38, 39],\n",
       " [12, 37, 38, 39, 40],\n",
       " [12, 37, 38, 39, 40, 2],\n",
       " [12, 37, 38, 39, 40, 2, 41],\n",
       " [12, 37, 38, 39, 40, 2, 41, 42],\n",
       " [12, 37, 38, 39, 40, 2, 41, 42, 9],\n",
       " [12, 37, 38, 39, 40, 2, 41, 42, 9, 43],\n",
       " [11, 44],\n",
       " [11, 44, 10],\n",
       " [11, 44, 10, 1],\n",
       " [11, 44, 10, 1, 45],\n",
       " [11, 44, 10, 1, 45, 7],\n",
       " [11, 44, 10, 1, 45, 7, 46],\n",
       " [11, 44, 10, 1, 45, 7, 46, 2],\n",
       " [11, 44, 10, 1, 45, 7, 46, 2, 47],\n",
       " [11, 44, 10, 1, 45, 7, 46, 2, 47, 48],\n",
       " [11, 44, 10, 1, 45, 7, 46, 2, 47, 48, 12],\n",
       " [11, 44, 10, 1, 45, 7, 46, 2, 47, 48, 12, 4],\n",
       " [11, 44, 10, 1, 45, 7, 46, 2, 47, 48, 12, 4, 5],\n",
       " [11, 44, 10, 1, 45, 7, 46, 2, 47, 48, 12, 4, 5, 6],\n",
       " [11, 44, 10, 1, 45, 7, 46, 2, 47, 48, 12, 4, 5, 6, 49],\n",
       " [11, 44, 10, 1, 45, 7, 46, 2, 47, 48, 12, 4, 5, 6, 49, 3],\n",
       " [11, 44, 10, 1, 45, 7, 46, 2, 47, 48, 12, 4, 5, 6, 49, 3, 50],\n",
       " [11, 44, 10, 1, 45, 7, 46, 2, 47, 48, 12, 4, 5, 6, 49, 3, 50, 51],\n",
       " [52, 53],\n",
       " [52, 53, 54],\n",
       " [52, 53, 54, 6],\n",
       " [52, 53, 54, 6, 55],\n",
       " [52, 53, 54, 6, 55, 56],\n",
       " [52, 53, 54, 6, 55, 56, 57],\n",
       " [52, 53, 54, 6, 55, 56, 57, 58],\n",
       " [52, 53, 54, 6, 55, 56, 57, 58, 3],\n",
       " [52, 53, 54, 6, 55, 56, 57, 58, 3, 59],\n",
       " [52, 53, 54, 6, 55, 56, 57, 58, 3, 59, 1],\n",
       " [52, 53, 54, 6, 55, 56, 57, 58, 3, 59, 1, 2],\n",
       " [52, 53, 54, 6, 55, 56, 57, 58, 3, 59, 1, 2, 60],\n",
       " [52, 53, 54, 6, 55, 56, 57, 58, 3, 59, 1, 2, 60, 61]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac970b33-b34f-47c1-965e-3993caf03808",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
